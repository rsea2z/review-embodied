\begin{abstract}
Embodied AI has recently moved from narrow task-specific control to broader Vision-Language-Action and world-model-based systems. This survey focuses on the data and training side of that transition. We organize the literature with three axes: \textbf{data provenance} (passive video, embodied interaction, synthetic/simulated), \textbf{state representation} (pixel, latent, object-centric), and \textbf{inference/training paradigm} (autoregressive, diffusion/flow-based, reinforcement-style post-training). We then analyze how large cross-platform robot datasets (e.g., Open X-Embodiment \cite{collaboration_open_2025}), world-model architectures (e.g., $\pi_0$ \cite{black__0_2026}), and simulator/data-engine pipelines interact in modern embodied learning. A comparative summary table is provided to distinguish \textbf{algorithm-oriented} and \textbf{data-oriented} studies within a unified survey structure. Finally, we discuss open problems in physical consistency, long-horizon decision quality, robustness under distribution shift, and evaluation protocols for real-world deployment.
\end{abstract}
