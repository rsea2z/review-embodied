\begin{abstract}
Embodied intelligence requires agents to perceive, reason, and act under real-world physical constraints while adapting online to new tasks and environments. Over the last year, the field has rapidly shifted from modular pipelines toward large-scale vision-language-action (VLA) policies and world-model-based control stacks, with increasing emphasis on long-horizon robustness, data efficiency, and cross-embodiment transfer \citep{liang_large_2025,liu_aligning_2025,li_comprehensive_2025,fung_embodied_2025}. This survey reviews research from January 2024 to February 2026 and organizes the literature with a coupled framework: an embodied-agent pipeline view (perception, planning, control, adaptation) and a world-model design view (functionality, temporal modeling, and spatial representation). We synthesize representative advances in foundation VLAs, embodied world models, policy refinement, and benchmark design \citep{kim_openvla_2024,intelligence__05_2025,black__0_2026,team_gigaworld-0_2025,chen_bridgev2w_2026,upadhyay_worldbench_2026}. We further formalize the common learning objective that links latent dynamics modeling with decision optimization, clarifying where current systems gain performance and where they fail under distribution shift, partial observability, and closed-loop compounding errors \citep{gupta_essential_2024,wan_worldagen_2025,team_gigabrain-0_2025}. We conclude with concrete priorities on physical consistency, embodiment-aware representation, and safe continual adaptation for real deployment.
\end{abstract}

\noindent\textbf{Keywords:} embodied AI, world models, vision-language-action models, robotic foundation models, long-horizon planning
