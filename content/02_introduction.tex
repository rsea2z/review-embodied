\section{Introduction}
\label{sec:introduction}

Embodied AI studies agents that close the full interaction loop with the physical world: multimodal sensing, state estimation, goal-conditioned reasoning, action planning, and low-level motor execution under uncertainty, latency, and resource constraints. Unlike disembodied systems that operate purely on stored data, embodied agents must continuously reconcile internal representations with dynamic environmental feedback, handle partial observability and irreversibility, and recover from failures in real time. This fundamental challenge---bridging the semantic richness of large language and vision models with the physical precision of real-world control---defines the central research agenda of the current period.

Recent progress has been striking. As of early 2026, generalist robot policies can follow open-ended natural language instructions for dexterous household manipulation \citep{black__0_2026,intelligence__05_2025}, humanoid systems demonstrate whole-body loco-manipulation in unstructured environments \citep{nvidia_gr00t_2025,jiang_wholebodyvla_2025,ding_humanoid-vla_2025}, and world-model-guided stacks generate physically plausible synthetic data at scale to mitigate real-robot collection costs \citep{team_gigaworld-0_2025,team_gigabrain-0_2025,nvidia_cosmos_2025}. In parallel, VLA architectures have proliferated dramatically, with specialized variants addressing 3D spatial reasoning \citep{qu_spatialvla_2025,sun_geovla_2025,zhang_4d-vla_2025,li_3ds-vla_2025}, tactile and force feedback \citep{bi_vla-touch_2025,huang_tactile-vla_2025,yu_forcevla_2025}, chain-of-thought reasoning \citep{ye_vla-r1_2025,zhao_cot-vla_2025,zhang_reasoning-vla_2025,huang_graphcot-vla_2025}, reinforcement post-training \citep{li_vla-rft_2025,lu_vla-rl_2025,chen_conrft_2025,zang_rlinf-vla_2025}, efficiency and edge deployment \citep{pertsch_fast_2025,yang_efficientvla_2025,wen_tinyvla_2025,shukor_smolvla_2025,budzianowski_edgevla_2025}, and autonomous driving \citep{guo_vdrive_2025,li_drivevla-w0_2025,hao_driveaction_2025,jiang_survey_2025}. The breadth and pace of this progress make a unified, decision-oriented synthesis both timely and necessary.

\subsection{Hook: The Embodied Intelligence Imperative}

The goal of building machines that act intelligently in the physical world has motivated AI research for decades. Early symbolic approaches modeled the physical world through explicit ontologies and geometric planning routines but struggled with perceptual grounding, uncertainty propagation, and the combinatorial complexity of real environments. Deep learning transformed this landscape by enabling end-to-end visuomotor mappings from raw pixels to actions, but at the cost of data hunger, poor sample efficiency, and weak generalization beyond training distributions.

The transformative insight of the current period is that \emph{world models}---internal simulators of environment dynamics---can bridge this gap by providing:
\begin{enumerate}
    \item \textbf{Predictive grounding}: anticipating the consequences of candidate actions before executing them, enabling safer and more deliberate behavior.
    \item \textbf{Data amplification}: generating synthetic training data that would be prohibitively expensive or dangerous to collect physically.
    \item \textbf{Counterfactual reasoning}: evaluating hypothetical action sequences under varying conditions to improve robustness to distribution shift.
    \item \textbf{Representation learning}: structuring internal features around controllable scene dynamics rather than raw pixel correlation, enabling better transfer.
\end{enumerate}

In parallel, large-scale vision-language pretraining has endowed policy networks with deep semantic understanding of instructions, objects, and goals. The synthesis of these two trends---language-grounded semantic reasoning and physically grounded world modeling---represents the defining architectural shift of 2024--2026.

\subsection{Motivation and Historical Context}

\textbf{Cognitive foundations.} The concept of an internal model of the environment was articulated by \citet{batra_rearrangement_2020} and formalized earlier by control theorists as the ``internal model principle.'' From a cognitive science perspective, rich internal representations of world dynamics are considered foundational to intelligent planning and generalization in biological agents. This perspective motivated a long line of model-based reinforcement learning research and foreshadowed the current wave of neural world models for embodied control.

\textbf{Phase~1: Task definition and environment grounding (2020--2022).} The field began with clear delineation of canonical embodied tasks. Interactive instruction following, rearrangement-centered evaluation, and open-ended goal pursuit established the core challenge of bridging perception with executable skill libraries \citep{batra_rearrangement_2020,duan_survey_2022}. Early multimodal agents demonstrated that language could structure complex sequential behaviors, but relied heavily on symbolic planners that were brittle under perceptual ambiguity \citep{gao_dialfred_2022}. Open-ended survival and exploration settings underscored the importance of lifelong skill accumulation and self-guided curriculum construction \citep{fan_minedojo_2022}. These works collectively established the benchmark infrastructure that subsequent approaches would be measured against.

\textbf{Phase~2: Language-grounded planning (2022--2023).} The next phase recognized that large language models, trained on vast internet corpora, could serve as implicit world knowledge bases for embodied planning. SayCan demonstrated that LLM-generated action plans could be grounded by value functions that estimate physical feasibility \citep{ahn_as_2022}. Inner Monologue showed that environmental language feedback---natural language descriptions of what happened after an action---dramatically improved task completion by closing the perception-action loop at the semantic level \citep{huang_inner_2022}. Subsequent works refined this paradigm: LLM-Planner enabled open-vocabulary spatial navigation through in-context learning \citep{song_llm-planner_2023}; Plan-and-Solve decomposed reasoning from execution \citep{wu_plan_2023}; JARVIS combined neuro-symbolic reasoning with modular execution for dialogue-conditioned task completion \citep{zheng_jarvis_2025}; VoxPoser synthesized 3D affordance and value maps from language descriptions to guide manipulation \citep{huang_voxposer_2023}. The grounded decoding paradigm further showed that semantic constraints could directly modulate token generation for physical feasibility \citep{huang_grounded_2023}. Meanwhile, Voyager demonstrated that GPT-4 could iteratively design, refine, and accumulate executable skill libraries for open-ended agents \citep{wang_voyager_2023}.

\textbf{Phase~3: Foundation policies and data scaling (2022--2023).} A parallel line of work moved beyond language-only planners to build generalist visuomotor control policies at scale. Gato demonstrated that a single transformer could be trained on heterogeneous multi-domain data spanning games, robotic control, and language tasks \citep{reed_generalist_2022}. RT-1 established transformer-based real-robot manipulation from diverse task demonstrations collected via large-scale data pipelines \citep{brohan_rt-1_2023}. Q-Transformer extended this to offline RL over large datasets while preserving the autoregressive token prediction interface \citep{chebotar_q-transformer_2023}. RoboCat demonstrated few-shot adaptation across robot embodiments and tasks through self-improvement loops \citep{bousmalis_robocat_2023}. PaLM-E showed that embodied policies could benefit from grounding large multimodal language models with physical sensorimotor data \citep{driess_palm-e_2023}. VIMA unified manipulation commands across heterogeneous task types through multimodal prompt engineering \citep{jiang_vima_2023}. RT-Trajectory and Code-as-Policies explored trajectory-sketch and code-mediated control interfaces \citep{gu_rt-trajectory_2023,liang_code_2023}. BridgeData V2 and ACT-style teleoperation recipes accelerated data collection for low-cost manipulation systems \citep{walke_bridgedata_2023,zhao_learning_2023}. Diffusion Policy established denoising diffusion as a powerful generative framework for visuomotor control that naturally handles multimodal action distributions \citep{chi_diffusion_2024}. These works created the foundation on which the 2024--2026 generation would build.

\textbf{Phase~4: VLA scaling and world-model integration (2024--2026).} The current phase is characterized by three overlapping trends. First, open-source and closed VLA models scaled to 7B--70B parameters, with OpenVLA demonstrating state-of-the-art open-source manipulation across 29 tasks while outperforming closed models such as RT-2-X (55B) with 7$\times$ fewer parameters \citep{kim_openvla_2024}. Second, specialized architectural innovations proliferated to address VLA limitations: flow-matching policies for dexterous control \citep{black__0_2026}, frequency-space action tokenization for high-frequency tasks \citep{pertsch_fast_2025}, hybrid autoregressive-diffusion architectures \citep{liu_hybridvla_2025}, and dual-system designs separating slow reasoning from fast motor execution \citep{nvidia_gr00t_2025}. Third, world models were tightly coupled with VLA pipelines: WorldVLA unified action prediction with future image synthesis in a single autoregressive stack \citep{cen_worldvla_2025}, BridgeV2W aligned coordinate-space actions with pixel-space predictions through URDF-rendered embodiment masks \citep{chen_bridgev2w_2026}, and GigaWorld-0/GigaBrain-0 established world models as data engines to generate training distributions at scale \citep{team_gigaworld-0_2025,team_gigabrain-0_2025}.

\subsection{Why a New Survey Is Needed}

Multiple surveys have examined embodied AI, VLA models, and world models from various angles in the 2024--2026 period. Liu et al.\ provide a broad panorama of multimodal large model alignment for embodied AI but give limited treatment to the algorithmic coupling between world modeling and control optimization \citep{liu_aligning_2025}. Liang et al.\ survey large model empowered embodied AI with strong coverage of hierarchical and end-to-end decision paradigms but a less systematic taxonomy of world-model design choices \citep{liang_large_2025}. Li et al.\ provide the most taxonomically complete world-model survey to date \citep{li_comprehensive_2025}, while Ding et al.\ give a broader but less embodiment-focused treatment \citep{ding_understanding_2025}. Zhong et al.\ and Yu et al.\ survey the VLA methodology landscape \citep{zhong_survey_2025,yu_survey_2026}. Jiang et al.\ cover VLA for autonomous driving specifically \citep{jiang_survey_2025}. Fung et al.\ emphasize the world model as the core reasoning component for embodied agents \citep{fung_embodied_2025}.

Despite this growing body of work, three specific gaps remain unaddressed.

\textbf{Gap 1: Decision-coupling perspective.} Existing surveys organize methods either by application domain or by neural architecture class. Neither framing adequately captures the design choice that most predicts deployment behavior: whether the world model is directly coupled with the decision objective or decoupled for general-purpose pretraining. Decision-coupled models can achieve higher task-specific reliability but require careful data pipeline design; general-purpose models offer broader transfer but often need explicit post-training adaptation to reach target performance. This axis has not been systematically studied.

\textbf{Gap 2: 2024--2026 VLA diversity.} The VLA literature has expanded dramatically in 2025 to include models addressing spatial and geometric perception \citep{qu_spatialvla_2025,sun_geovla_2025,li_3ds-vla_2025,bhat_3d_2025}, multi-sensory fusion beyond vision \citep{bi_vla-touch_2025,huang_tactile-vla_2025,yu_forcevla_2025,wei_audio-vla_2025}, chain-of-thought and reinforcement reasoning \citep{ye_vla-r1_2025,guo_vla-reasoner_2025,yin_deepthinkvla_2025}, whole-body humanoid control \citep{jiang_wholebodyvla_2025,ding_humanoid-vla_2025}, multi-robot coordination \citep{sun_collabvla_2025,guo_embodied_2024,li_embodied_2025}, and safety-aware deployment \citep{zhang_safevla_2025,hancock_run-time_2025}. No existing survey provides systematic coverage of this breadth.

\textbf{Gap 3: Deployment-centered evaluation.} Recent work has begun exposing that standard benchmark scores are poor proxies for deployment reliability. WorldBench targets disentangled physical concept evaluation \citep{upadhyay_worldbench_2026}; Wu et al.\ analyze what video generation models understand about physics \citep{wu_what_2026}; Valle et al.\ argue for uncertainty and quality metrics beyond binary success \citep{valle_evaluating_2025}; Wu et al.\ systematically expose pragmatic failure modes \citep{wu_pragmatic_2026}. These diagnostic perspectives need integration into a unified framework.

\subsection{Technical Lineage Before 2024}

The current wave is built on three earlier lines of work. The first established canonical embodied tasks and open environments---rearrangement evaluation benchmarks and open-ended skill acquisition settings---motivating closed-loop success criteria and environment diversity requirements \citep{batra_rearrangement_2020,duan_survey_2022,fan_minedojo_2022}. This line also developed multimodal dialogue-conditioned benchmarks such as DialFRED \citep{gao_dialfred_2022} and open-ended task completion in realistic household simulators.

The second line developed language-grounded planning with explicit feasibility checks and environment feedback \citep{ahn_as_2022,huang_language_2022,huang_inner_2022,song_llm-planner_2023,wu_plan_2023,wu_embodied_2023,huang_grounded_2023,sarch_open-ended_2023,zheng_jarvis_2025}. In our notation, this work introduced the high-level/low-level policy factorization, where a language plan $\xi_t$ conditions a motor-execution policy, foreshadowing modern VLA architectures that maintain semantic and motor heads simultaneously.

The third line established foundation-policy recipes for robot control at scale through heterogeneous imitation learning and transformer-based control \citep{reed_generalist_2022,brohan_rt-1_2023,chebotar_q-transformer_2023,bousmalis_robocat_2023,driess_palm-e_2023,jiang_vima_2023,liang_code_2023,gu_rt-trajectory_2023,huang_voxposer_2023,walke_bridgedata_2023,zhao_learning_2023,wang_voyager_2023,chi_diffusion_2024}. These developments yielded the action tokenization, data scaling, and VLM initialization insights that 2024--2026 systems inherit and extend.

\subsection{Scope and Inclusion Criteria}

This survey covers publications from \textbf{January 1, 2024 to February 27, 2026}. A work is in scope if it:
\begin{itemize}
    \item proposes methods or benchmarks for embodied agents that interact with physical environments through robotic control, autonomous driving, or situated simulation;
    \item involves world modeling, VLA architectures, embodied data pipelines, or evaluation protocols for closed-loop physical tasks; or
    \item provides analysis directly relevant to coupling world models with embodied decision-making objectives.
\end{itemize}
Purely generic video generation models without embodiment-specific coupling, and general-purpose language models without grounding to physical action spaces, are excluded from the main technical analysis but discussed as precursors where historically relevant.

We adopt two synchronized analytical views:
\begin{itemize}
    \item \textbf{Embodied pipeline view:} how perception, planning/reasoning, control, and adaptation components are composed and what interfaces connect them.
    \item \textbf{World-model design view:} functionality coupling, temporal modeling horizon, and spatial representation form.
\end{itemize}

\subsection{Contributions}

This survey makes five concrete contributions:
\begin{enumerate}
    \item \textbf{Unified decision-oriented taxonomy}: we propose a three-axis taxonomy (functionality coupling, temporal modeling, spatial representation) that predicts deployment behavior more faithfully than architecture-centric or application-centric classifications.
    \item \textbf{Mathematical formalization}: we derive a shared learning objective that links POMDP-based embodied control with latent world-model training, unifying formulations scattered across individual papers.
    \item \textbf{Comprehensive 2024--2026 coverage}: we systematically analyze 318 papers across foundation VLA policies, world-model-guided control stacks, post-training reinforcement refinement, efficiency-oriented adaptation, humanoid and multi-modal systems, autonomous driving, and embodied benchmarks.
    \item \textbf{Cross-family quantitative perspective}: we compare method families under a normalized decision utility framework and identify a recurrent two-stage recipe (large prior followed by decision-coupled adaptation) as the dominant empirical pattern.
    \item \textbf{Deployment-oriented challenge synthesis}: we distill six open challenges grounded in concrete empirical failures reported across the literature, each with specific research priority recommendations.
\end{enumerate}

\subsection{Paper Organization}

Section~\ref{sec:background} introduces mathematical foundations for embodied control and latent world-model training. Section~\ref{sec:taxonomy} presents the three-axis taxonomy, interface contracts, and embodied pipeline mapping with comprehensive method coverage. Section~\ref{sec:data-metrics} surveys data regimes, curation dimensions, benchmark categories, and evaluation metric families. Section~\ref{sec:comparison} provides cross-family comparison including method-level tables, case studies, and the two-stage pattern analysis. Section~\ref{sec:challenges} distills six open challenges with near-term research priorities. Section~\ref{sec:conclusion} concludes with a synthesis of the current frontier and outlook.
