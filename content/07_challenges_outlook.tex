\section{Open Challenges and Outlook}
\label{sec:challenges}

The cross-family analysis in Section~\ref{sec:comparison} reveals that no single method family dominates across all deployment dimensions. The following seven challenges distill the most persistent gaps---each grounded in concrete empirical failures documented in the literature---and identify near-term research priorities that would most effectively advance the field.

\subsection{Challenge 1: Long-Horizon Physical Consistency}

Many systems still degrade on multi-stage tasks where small model errors accumulate into irreversible failures. As formalized in Section~\ref{sec:background} (Eq.~\ref{eq:drift}), rollout error can grow exponentially with the Lipschitz constant of the dynamics model, making long-horizon plans unreliable even when single-step prediction is accurate. WorldBench diagnoses this through concept-level physical evaluation that isolates specific failure modes rather than reporting entangled aggregate metrics \citep{upadhyay_worldbench_2026}.

Two technical gaps are central. First, weak causal invariants under contact and object rearrangement allow models to exploit visual shortcuts that fail under scene perturbation---Eva-VLA demonstrates that all tested VLA models exhibit over 60\% failure rates under modest physical variations, with up to 97.8\% failure in long-horizon settings \citep{liu_eva-vla_2025}. Second, limited uncertainty calibration in long-horizon rollouts causes planners to over-trust model predictions, producing brittle control sequences under distribution shift. Mechanistic and semantic-consistency approaches address this by enforcing physically grounded prediction structure \citep{wang_mechanistic_2026,berg_semantic_2025}. Future work should prioritize physically grounded temporal constraints and intervention-aware planning objectives, not only visual realism metrics \citep{gupta_essential_2024,team_gigabrain-0_2025}.

Long-VLA provides a concrete architectural response: a phase-aware input masking strategy segments subtasks into moving and interaction phases, enabling the first end-to-end VLA model for long-horizon tasks and introducing the L-CALVIN benchmark for systematic long-horizon evaluation \citep{fan_long-vla_2025}. DreamVLA addresses long-horizon consistency through dynamic-region-guided world knowledge prediction that integrates spatial and semantic cues, achieving 4.44 average task length on CALVIN ABC-D \citep{zhang_dreamvla_2025}.

\subsection{Challenge 2: Embodiment-Aware Representation Alignment}

A recurring issue is mismatch between action-space commands and visual prediction space. Approaches that inject embodiment structure (kinematics, camera geometry, contact priors) are promising but not yet standardized \citep{chen_bridgev2w_2026,guo_flowdreamer_2026,sun_geovla_2025}. \citet{li_vla_2025} provide a precise diagnosis: VLA brittleness arises primarily from spatial modeling misalignment rather than physical modeling deficits. Their Feature Token Modulation improves viewpoint accuracy from 48.5\% to 87.1\% with only 4,000 parameters, while Feature Linear Adaptation achieves 90.8\%---demonstrating that alignment, not capacity, is the binding constraint. ReVLA addresses a complementary visual domain limitation by reverting distribution shift in the visual encoder, restoring manipulation accuracy under novel backgrounds and lighting \citep{dey_revla_2025}. Similarly, \citet{kachaev_dont_2025} demonstrate that aligning visual representations for out-of-distribution generalization---rather than scaling backbone capacity---yields large robustness gains under domain shift.

This mismatch is no longer a niche issue; it affects generalization across robot morphologies, viewpoint changes, and tool-based manipulation. Align-Then-Steer addresses cross-embodiment transfer through a VAE-based plug-and-play adaptation framework that embeds target actions into the pre-training latent distribution. This approach achieves +9.8\% in simulation and +32\% in real-world cross-embodiment settings \citep{zhang_align-then-steer_2025}. InSpire demonstrates that intrinsic spatial reasoning---prepending ``In which direction is [object] relative to robot?'' queries to VLA inputs---mitigates spurious correlations without additional training data \citep{zhang_inspire_2025}. A key direction is to define representation interfaces that are simultaneously planner-friendly, control-grounded, and computationally efficient.

\subsection{Challenge 3: Evaluation for Deployment, Not Only Benchmarks}

Benchmark success remains an incomplete proxy for field reliability. LIBERO-Plus reveals that performance drops from 95\% to below 30\% under modest perturbations across seven dimensions. Moreover, models are largely insensitive to language variations, suggesting they tend to ignore instructions entirely rather than failing to parse them \citep{fei_libero-plus_2025}. VLATest's fuzzing framework systematically exposes lack of robustness under confounding objects, lighting, camera poses, unseen objects, and instruction mutations across all seven evaluated VLA models \citep{wang_vlatest_2025}. The community needs shared protocols that jointly evaluate safety, recovery, intervention rate, and sustained task throughput under shift \citep{upadhyay_worldbench_2026,wu_what_2026,valle_evaluating_2025}.

In particular, evaluation suites should move from single-episode success to \emph{session-level reliability}, including repeated-task stability, failure recovery quality, and operator load over extended runtime. The systematic review by \citet{din_vision_2025}, analyzing 102 VLA models, 26 datasets, and 12 simulation platforms, provides a comprehensive framework for understanding the current evaluation landscape, while \citet{zhang_step_2025} examine approaches exhibiting core world model capabilities to identify what a fully realized evaluation framework should assess.

\subsection{Challenge 4: Data Governance and Compute Efficiency}

Scaling trends improve capability but increase data, compute, and reproducibility burdens. Efficient adaptation, model compression, and transparent data curation are central for practical adoption \citep{guan_efficient_2025,yang_efficientvla_2025,shen_efficient_2026}.

Data governance is equally important: licensing, robot-operator privacy, and intervention traceability will increasingly influence which datasets can be reused for large-scale embodied pretraining. The survey by \citet{lu_multimodal_2025} identifies five storage architectures and five retrieval paradigms for embodied AI data, highlighting that the physical grounding gap and cross-modal integration challenges grow with dataset heterogeneity. As embodied datasets approach internet scale---Open X-Embodiment already aggregates data from 22 robots across 21 institutions \citep{collaboration_open_2025}---governance frameworks must evolve beyond current ad-hoc practices.

On the efficiency front, recent results demonstrate that substantial capability can be preserved under aggressive compression. DynamicVLA achieves real-time dynamic object manipulation with a 0.4B-parameter model through continuous inference and latent-aware action streaming \citep{xie_dynamicvla_2026}. CEED-VLA achieves $4\times$ inference acceleration through consistency distillation \citep{song_ceed-vla_2025}. These results suggest that the efficiency-capability frontier can be pushed further with careful architectural choices.

\subsection{Challenge 5: Continual Adaptation Under Safety Constraints}

Recent post-training results indicate that online adaptation is a major performance driver, but safe adaptation protocols are still immature \citep{intelligence__06_2025,li_vla-rft_2025,lu_vla-rl_2025}. Open questions include how to schedule exploration under hard safety budgets, how to integrate teleoperator corrections without destabilizing pretrained priors, and how to prevent catastrophic forgetting during continual specialization.

SafeVLA provides a concrete starting point by framing VLA safety as a constrained MDP problem, reducing cumulative safety violation cost by 83.58\% while maintaining task success through min-max optimization \citep{zhang_safevla_2025}. FPC-VLA introduces a dual-model framework where a supervisor evaluates action viability via vision-language queries and generates corrective strategies, outperforming baselines on both SIMPLER and LIBERO \citep{yang_fpc-vla_2025}. On-the-fly VLA adaptation via test-time RL (TT-VLA) enables policy adaptation during inference using dense reward signals from step-by-step task-progress monitoring while preserving SFT and RL-trained priors \citep{liu_--fly_2026}. Dual-Actor fine-tuning demonstrates that human corrections can be converted into language commands for RL-based adaptation, achieving 100\% success within 101 minutes of online training \citep{jin_dual-actor_2025}. However, scaling these approaches to diverse deployment scenarios while maintaining safety guarantees remains an open challenge.

\subsection{Challenge 6: Multi-Agent and Social Coordination}

Beyond single-agent adaptation, embodied systems increasingly operate alongside other agents---both cooperative and adversarial. In driving and cooperative manipulation, multi-agent dynamics create failure modes that are invisible in single-agent benchmarks. The transition from single-agent to multi-agent embodied systems introduces coordination, communication, and social compliance as first-class design requirements.

CollabVLA introduces a self-reflective framework that transforms standard visuomotor policies into collaborative assistants through an MoE design integrating VLM-based reflective reasoning with diffusion-based action generation. This design cuts normalized task time by approximately $2\times$ and dream counts by $4\times$ compared to generative agent baselines \citep{sun_collabvla_2025}. CoELA demonstrates that modular frameworks integrating LLMs with perception, memory, and execution modules enable effective multi-agent cooperation, with GPT-4-driven agents surpassing planning-based methods on cooperative household tasks \citep{zhang_building_2024}. Organized team structures imposed through prompt-based designs improve cooperation quality through criticize-reflect processes for enhanced coordination \citep{guo_embodied_2024}. The review by \citet{li_embodied_2025} provides a comprehensive treatment of embodied multi-agent systems.

Key open problems include: (i) establishing shared world models that support coordinated planning across agents with different sensing and actuation capabilities; (ii) defining coordination metrics that capture both task efficiency and social compliance; (iii) scaling multi-agent embodied learning beyond tabletop cooperative tasks to household-scale and urban-scale environments; and (iv) handling adversarial or uncooperative agents in shared spaces.

\subsection{Challenge 7: Interpretability and Trustworthiness}

As VLA systems move toward deployment in safety-critical settings, interpretability and trustworthiness become necessary rather than optional. The opacity of end-to-end VLA models creates certification challenges and limits operator trust.

\citet{haon_mechanistic_2025} provide the first framework for mechanistic interpretation and steering of VLAs. By projecting feedforward activations onto token embedding bases, they identify sparse semantic directions (speed, direction) that can steer VLA behavior at inference time without fine-tuning---demonstrating that VLA internals are more structured and interpretable than previously assumed. \citet{pugacheva_bring_2025} expose a complementary vulnerability: semantically similar irrelevant context in embodied AI commands can trigger up to 50\% quality decline in VLA outputs, while LLM-based filtering recovers up to 98.5\% of original performance. VLA-Mark introduces cross-modal watermarking for policy provenance and integrity verification, addressing the growing need for model authentication in deployment \citep{liu_vla-mark_2025}. VLA-OS provides OS-style abstractions for structured planning and monitoring, with controlled experiments revealing that visually grounded planning paradigms generally outperform language-only planning \citep{gao_vla-os_2025}. SafeVLA frames the trustworthiness problem formally through constrained optimization, reducing safety violations by 83.58\% while preserving task performance \citep{zhang_safevla_2025}. Beyond safety, \citet{hsieh_what_2025} demonstrate that VLAs can be trained to reject physically impossible instructions, introducing a capability-awareness dimension that prevents execution of infeasible commands. \citet{wang_exploring_2025} systematically explore adversarial vulnerabilities of VLA models in robotic settings, revealing that targeted perturbations to visual inputs can cause catastrophic policy failures even under benign task conditions.

Key open problems include: (i) developing causal rather than correlative explanations of VLA behavior under novel scenarios; (ii) creating online monitoring systems that can detect impending failures before they occur; (iii) establishing certification frameworks for embodied AI systems in regulated domains (medical, automotive, aviation); and (iv) designing human-VLA interfaces that convey appropriate levels of uncertainty and decision rationale.

\subsection{Scope Boundaries}

This survey focuses on embodied and decision-relevant world modeling within 2024--2026. Broader non-embodied world-model literature is therefore not covered in depth in the core analysis. The feature article by \citet{feng_embodied_2025} provides a high-level overview of the progression from LLMs to world models in embodied AI. Existing surveys provide complementary perspectives: \citet{dolgopolyi_bridging_2025} offer bibliometric analysis of VLM and VLA systems, \citet{li_survey_2025} provide a comprehensive review across five dimensions of VLA models, \citet{shao_large_2025} give the first systematic taxonomy of large VLM-based VLA architectures, and \citet{sapkota_vision-language-action_2026} review VLA applications across autonomous vehicles, medical robotics, agriculture, and humanoid systems. \citet{turgunbaev_perception_2025} provide a concise overview of integrated VLA systems from perception to action. In fast-moving boundary areas, such as generic video world models later adapted to robotics, category boundaries will likely continue to shift as deployment evidence accumulates.

\subsection{Near-Term Research Priorities}

We identify five near-term priorities that would most effectively advance embodied intelligence:

\textbf{Disentangled diagnostic evaluation} should shift from monolithic benchmark scores to concept-isolated physical diagnostics and reasoning-action faithfulness checks. WorldBench and the physics-understanding analysis by \citet{wu_what_2026} provide templates, but the community needs standardized toolkits that are as easy to deploy as existing benchmark suites \citep{upadhyay_worldbench_2026}.

\textbf{Action-world alignment under embodiment constraints} should improve coordinate-to-pixel and language-to-control alignment using geometry-aware conditioning and consistency objectives. The success of BridgeV2W's embodiment masks and InSpire's spatial reasoning queries demonstrates that explicit alignment mechanisms can yield large improvements with minimal architectural overhead \citep{chen_bridgev2w_2026,wang_unified_2025,chen_conrft_2025,zhang_inspire_2025}.

\textbf{Scalable but safe adaptation loops} should combine synthetic or world-model-generated data with intervention-aware online refinement to improve robustness without uncontrolled exploration cost. The $\pi_0$ lineage and VLA-RFT demonstrate the recipe; extending it with formal safety guarantees (as in SafeVLA) is the key remaining challenge \citep{team_gigaworld-0_2025,team_gigabrain-0_2025,intelligence__06_2025,li_vla-rft_2025,zhang_safevla_2025}.

\textbf{Multi-agent coordination benchmarks} are needed to move beyond single-agent evaluation. Current multi-agent embodied work is largely limited to tabletop cooperation and dialogue-conditioned tasks; scaling to household-scale and urban-scale coordination with heterogeneous agents remains underexplored \citep{sun_collabvla_2025,guo_embodied_2024,li_embodied_2025}.

\textbf{Interpretability-guided deployment} should make mechanistic understanding actionable for deployment decisions. The sparse semantic directions identified by \citet{haon_mechanistic_2025} suggest that VLA internals can be monitored and steered in principled ways; integrating such tools into deployment pipelines would improve both safety and operator trust.

\subsection{Outlook}

We expect the next phase of embodied intelligence to converge on hybrid systems that combine reusable foundation priors, decision-coupled world models, online adaptation under safety constraints, and standardized evaluation pipelines tied to real deployment targets.

The strongest near-term gains will likely come from better coupling between predictive modeling and actionable control feedback. The evidence from 2024--2026 consistently shows that even modest amounts of decision-coupled post-training (hundreds of online RL steps, teleoperator corrections over minutes rather than hours) can close substantial deployment gaps that pretraining alone cannot address \citep{intelligence__06_2025,li_vla-rft_2025,zang_rlinf-vla_2025}.

Mid-term progress will depend on three developments. First, standardized deployment-centric evaluation must replace benchmark-centric evaluation as the primary measure of progress---the current gap between benchmark scores and real-world reliability is unsustainable. Second, safer continual learning protocols that maintain formal guarantees during online adaptation will enable broader deployment in regulated domains. Third, multi-agent and social coordination capabilities will extend embodied AI from single-robot manipulation to household-scale, urban-scale, and eventually societal-scale collaboration.

The convergence of foundation-scale pretraining, efficient adaptation, world-model-guided reasoning, and deployment-oriented evaluation creates a favorable moment for embodied AI. The systems surveyed here demonstrate meaningful progress toward physically grounded, decision-aware intelligent agents, though the gap between benchmark performance and sustained real-world reliability remains substantial and defines the next phase of the field.
