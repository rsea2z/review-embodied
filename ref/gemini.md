# 2024-2025年度具身智能与世界模型：数据构建、训练范式与物理交互的演进深度综述

## 1. 引言：物理世界的基础模型时刻

在人工智能的发展历程中，2024年至2025年初标志着具身智能（Embodied AI）从“特定任务模仿”向“通用物理世界模拟与决策”的决定性范式转变。长期以来，机器人学习受限于真实物理数据的稀缺性与高昂采集成本，主要依赖于小规模的遥操作示教或特定环境下的强化学习。然而，随着大语言模型（LLM）和视觉生成模型（Video Generation Models）的爆发，学术界与工业界开始探索一条新的路径：利用互联网规模的视频数据构建“世界模型”（World Models），使其作为代理（Agent）的内部模拟器，以此来理解物理规律、预测未来状态，并最终指导决策。

本报告深入调研了近一年内的关键文献，分析发现这一时期的研究不再仅仅关注“如何让机器人动起来”，而是聚焦于“如何让机器人理解其动作对世界的影响”。这一转变催生了新的数据构建方法——从被动视频的物理化清洗到GPU并行仿真的海量合成；同时也推动了训练范式的革新——从简单的行为克隆（Behavior Cloning）演进为基于流匹配（Flow Matching）的轨迹生成和基于潜在空间的因果推理。本综述将详尽解构NVIDIA Cosmos、Meta V-JEPA 2、Physical Intelligence $\pi_0$、Google DeepMind Genie以及Open X-Embodiment等前沿工作，揭示其背后的数据量级、构造逻辑与训练细节，为专业研究人员提供一份详尽的技术图谱。

---

## 2. 世界模型的数据基石：互联网视频的物理化与表征学习

世界模型的核心假设在于，如果一个模型能够准确预测环境对某种干预的响应，那么它就掌握了环境的物理规律。为了训练这种模型，单纯的机器人交互数据（Ego-centric data）在规模上远远不够。因此，2024-2025年的主流趋势是利用互联网上数以亿计的“被动视频”（Passive Video），通过巧妙的数据工程和自监督训练目标，从中蒸馏出物理常识。

### 2.1 互联网视频的清洗与物理化工程：NVIDIA Cosmos

NVIDIA Cosmos 项目代表了当前将物理AI基础模型推向工业级规模的典型尝试。其核心洞察在于，并非所有视频都包含有效的物理信息，大量的互联网视频存在镜头切换频繁、缺乏动态或物理逻辑混乱的问题。因此，构建一个能够训练世界基础模型（World Foundation Models, WFMs）的数据集，首要任务是数据的“物理化清洗”。

#### 2.1.1 数据集规模与多阶段构成

Cosmos 的数据工程展示了从原始数据到训练数据的漏斗式筛选过程，其规模在同类研究中处于领先地位：

| 数据阶段 | 数据量级 | 描述与用途 |
| --- | --- | --- |
| 原始数据池 | > 2000万小时 | 未经处理的互联网视频，涵盖各种分辨率、帧率和内容。 |
| 预训练数据集 | ~ 1亿 ($10^8$) 片段 | 经过严格清洗的高质量视频片段，用于学习通用物理规律（如重力、碰撞）。 |
| 微调数据集 | ~ 1000万 ($10^7$) 片段 | 针对特定下游任务（如机器人操作、自动驾驶）的领域数据。 |

#### 2.1.2 Cosmos Curator：物理一致性的自动化筛选

为了处理如此庞大的数据量，NVIDIA 开发了名为 Cosmos Curator 的数据处理流水线 。该系统并非简单的数据过滤器，而是一个旨在最大限度保留“物理连贯性”的工程系统。

- 物理连贯的镜头检测（Shot Detection）：视频中的硬切（Hard Cut）或转场是世界模型训练的大忌，因为这种瞬间的像素突变不符合物理连续性。Cosmos Curator 采用高精度的镜头检测算法，将长视频切分为仅包含连续物理过程的短片段（Clip）。
- 运动过滤与动态评估（Motion Filtering）：静态画面对于学习动力学毫无价值。系统通过光流（Optical Flow）分析剔除静止或仅有摄像机轻微抖动的片段，确保保留的数据包含物体移动、形变或流体流动等显著的物理动态。
- 语义去重（Semantic Deduplication）：为了防止模型过拟合于某些高频出现的场景（如新闻播报背景），系统利用向量数据库对视频内容进行语义索引，确保数据的多样性覆盖。
- 合成数据的引入：除了真实视频，Cosmos 还大规模利用 NVIDIA Omniverse 生成合成数据。这部分数据通过程序化生成（Procedural Generation）构建，不仅包含像素信息，还附带完美的物理标注（如摩擦系数、质量、深度图），用于在后训练阶段增强模型对物理属性的理解 。

#### 2.1.3 训练范式：从预测到推理

Cosmos 的训练不仅限于视频生成，更引入了 Post-training 阶段来强化物理推理能力：

- 基础预训练：使用扩散Transformer（Diffusion Transformer, DiT）架构，在 $10^8$ 视频片段上进行下一帧预测和视频插帧训练。
- 监督微调（SFT）：引入 RoboVQA 等带有物理问答标注的数据集，微调模型以理解物体属性（例如，“这是玻璃，掉落会破碎”）。
- 强化学习推理（Cosmos Reason）：利用 Chain-of-Thought (CoT) 技术，结合强化学习（RL）优化模型的推理过程。例如，模型不仅要生成车祸后的画面，还需要在内部推理出“因为路面湿滑导致刹车距离变长”这一因果链条，从而生成符合逻辑的结果 。

### 2.2 掩码建模与潜在空间预测：Meta V-JEPA 2

与 Cosmos 试图生成高保真像素视频不同，Meta 的 V-JEPA 2 (Video Joint Embedding Predictive Architecture) 选择了一条更为抽象且高效的路径——在潜在空间（Latent Space）中预测特征 。这种方法回避了像素级生成的高昂计算成本，专注于学习环境的语义结构和动态变化。

#### 2.2.1 极高的数据效率

V-JEPA 2 的一个显著特征是其对机器人领域数据的极低依赖性，这得益于其强大的预训练表征能力：

- 预训练数据：约 100万小时 的互联网视频。这是一个纯被动观察数据集，不包含任何动作标签。
- 机器人微调数据：仅需 62小时 的机器人交互视频（来自 DROID 数据集）。相比于传统方法需要数千小时的机器人数据，V-JEPA 2 证明了通用的视觉表征可以极大地压缩下游任务所需的数据量。

#### 2.2.2 联合嵌入预测架构（JEPA）的训练逻辑

V-JEPA 2 的核心训练目标是 掩码建模（Masked Modeling），但与 BERT 或 MAE 不同，它预测的是特征而非原始信号：

1. 时空分块与掩码：将视频划分为时空块（Tubelets），并在时间维度上进行高比例的随机掩盖。
2. 特征预测：模型由上下文编码器（Context Encoder）和预测器（Predictor）组成。编码器处理可见的 Tubelets，预测器则尝试根据编码器的输出恢复被掩盖区域的潜在特征（由一个动量更新的目标编码器生成）。
3. 3D 旋转位置编码（3D-RoPE）：为了处理长视频序列中的时空关系，V-JEPA 2 引入了 3D-RoPE ，动态编码每个 Tubelet 的空间坐标和时间索引，使模型能够理解物体的轨迹和速度。

#### 2.2.3 机器人策略的零样本规划

在预训练完成后，V-JEPA 2 通过添加一个轻量级的 动作条件预测头（Action-Conditioned Prediction Head） 转化为世界模型。这个预测头在 62 小时的机器人数据上训练，学习 $z_{t+1} = P(z_t, a_t)$ 的映射关系。实验表明，这种模型具备 Zero-Shot 视觉规划能力：在未见过的环境中，给定目标图像，模型可以在潜在空间中搜索出一系列动作，使预测的特征状态逼近目标特征，而无需在当前环境中进行任何额外的微调。

### 2.3 生成式交互环境：Genie 的无监督动作抽象

Google DeepMind 的 Genie (Generative Interactive Environments)  提出了一种激进的数据利用思路：如何从没有任何动作标签的视频中，学习出一个可交互的“游戏”世界？

#### 2.3.1 从游戏视频到机器人数据

- 基础数据：30,000小时 的互联网 2D 平台游戏视频。这些视频仅包含画面，没有任何按键记录。
- 机器人扩展（GenieRedux）：后续研究将该方法应用于 RT-1 机器人数据集，证明了该架构在真实物理世界视频上的有效性。
- 数据预处理：视频被标准化为 16帧 的片段，共计约 680 万个样本。

#### 2.3.2 潜在动作模型（LAM）与无监督学习

Genie 的核心突破在于 潜在动作模型（Latent Action Model, LAM），它通过无监督的方式“发现”了动作：

- 视频分词器（Video Tokenizer）：使用 VQ-VAE 将高维视频帧压缩为离散的 Token 序列，降低了建模复杂度。
- 潜在动作推理：LAM 接收前后两帧图像 $(x_t, x_{t+1})$，预测连接这两帧的离散编码 $\hat{a}_t$。这个编码被视为“潜在动作”，代表了导致状态变化的某种抽象操作（如“跳跃”或“机械臂左移”）。
- 动力学模型（Dynamics Model）：一个参数量高达 10B 的时空 Transformer（ST-Transformer），以自回归的方式预测下一个 Token：$P(z_{t+1} | z_t, \hat{a}_t)$。
- 训练发现：Genie 的研究揭示了世界模型的 Scaling Law——随着模型参数（从 40M 到 2.7B+）和 Batch Size 的增加，生成的视频质量和物理一致性呈显著的幂律提升 。这表明，只要算力和数据足够，无监督学习物理交互是可行的。

---

## 3. 从视频生成到策略控制：扩散模型的因果化改造

虽然视频生成模型（如 Sora, DynamiCrafter）在画面质量上表现出色，但它们通常是为“生成一段好看的视频”而设计的，并非为“机器人控制”而设计。机器人控制需要严格的因果性（Causality）——未来的帧只能由过去的信息和当前的动作决定，不能依赖未来的信息。因此，将视频扩散模型改造为交互式世界模型成为了一个关键研究方向。

### 3.1 Vid2World：扩散模型的因果化与动作引导

Vid2World  系统地解决了视频扩散模型无法直接用于交互式控制的痛点。

#### 3.1.1 视频扩散因果化（Video Diffusion Causalization）

标准的视频扩散模型通常使用双向注意力机制（Bidirectional Attention），即生成第 $t$ 帧时会参考第 $t+1$ 帧的信息。Vid2World 对此进行了架构手术：

- 因果掩码（Causal Masking）：在时间注意力层（Temporal Attention）中引入三角掩码，强制模型只能关注 $t$ 时刻之前的特征。
- 权重迁移（Weight Transfer）：对于时间卷积层，直接截断未来的感受野会破坏预训练权重。Vid2World 提出了一种混合权重迁移机制，重新分配卷积核权重，在保留预训练特征提取能力的同时实现因果约束。
- 扩散强迫（Diffusion Forcing）：这是训练目标的关键调整。传统的扩散训练对所有帧施加相同的噪声水平，而 Vid2World 采用了 独立噪声采样。在训练时，前序帧（Context）保持清晰或低噪声，而当前预测帧施加高噪声。这迫使模型学会根据清晰的历史来去噪当前的未来，模拟了自回归生成的推理过程。

#### 3.1.2 因果动作引导（Causal Action Guidance）

为了让生成的视频受控于机器人动作，Vid2World 引入了 Classifier-Free Guidance 的变体：

- 在扩散模型的输入中注入动作向量。
- 训练时以一定概率随机丢弃动作条件。
- 推理时，通过线性组合有动作条件和无动作条件的噪声预测，放大动作对生成结果的影响力（Guidance Scale）。这种机制使得模型生成的视频严格遵循输入的控制指令，实现了从“视频生成”到“视频模拟”的跨越。

### 3.2 Cosmos Policy：单阶段的视频-策略转化

NVIDIA 的 Cosmos Policy  展示了更为直接的转化路径。它没有引入复杂的额外模块，而是直接利用预训练的 Cosmos-Predict2 视频模型作为策略本身。

- 数据集：利用 LIBERO 和 RoboCasa 等仿真基准数据，以及真实世界的双手操作数据。
- 训练方法：
   - 动作即潜在帧：创造性地将机器人的动作编码为视频生成过程中的 潜在帧（Latent Frames）。在模型的视角里，输出动作与输出图像像素没有本质区别，都是对未来的一种预测。
   - 价值函数生成：模型不仅预测未来的图像和动作，还预测未来的预期回报（Value），这为推理时的轨迹优选提供了依据。

- 性能：这种方法在 LIBERO 基准上达到了 98.5% 的惊人成功率，显著超越了从头训练的扩散策略。这强有力地证明了大规模视频预训练所蕴含的时空先验知识，对于策略学习具有极高的迁移价值。

---

## 4. 仿真革命：合成数据与Sim-to-Real的自动化

2024年是具身智能数据来源发生根本性逆转的一年。随着 GPU 并行仿真技术和 LLM 辅助设计的成熟，合成数据不再是真实数据的廉价替代品，而是成为了解决长尾分布和物理鲁棒性的主力军。

### 4.1 ManiSkill3：GPU 并行仿真的数据吞吐革命

ManiSkill3  的发布标志着机器人仿真进入了海量数据时代。其核心贡献在于解决了“速度”与“多样性”的矛盾。

#### 4.1.1 异构并行仿真（Heterogeneous Parallel Simulation）

传统的并行仿真通常是在多个环境中重复完全相同的任务（仅随机种子不同）。ManiSkill3 实现了 异构并行，即在单个 GPU 上同时运行数千个完全不同的环境。

- 场景构造：集成 PartNet Mobility（可交互家具/物体）和 ReplicaCAD（高保真室内场景），构建了涵盖移动操作、人形机器人、灵巧手操作等 12 个领域的任务库。
- 数据吞吐量：在 NVIDIA RTX 4090 上，ManiSkill3 可实现 30,000+ FPS 的 RGBD + 分割图生成速度。这意味着在几分钟内即可生成以往需要数小时采集的数据量。

#### 4.1.2 Real2Sim 与数字孪生

ManiSkill3 不仅用于生成随机数据，还提供了 Real2Sim 工具链，能够将真实世界的物体和场景快速重建为数字孪生。这使得研究人员可以在仿真中以 100 倍于实时的速度评估策略，极大地加速了 Sim-to-Real 的迭代周期。

### 4.2 DrEureka：LLM 驱动的自动化 Sim-to-Real

DrEureka  解决了一个长期困扰 Sim-to-Real 的难题：如何设计奖励函数和物理参数的随机化范围？

#### 4.2.1 LLM-in-the-Loop 的数据生成流程

DrEureka 将 LLM 引入到了数据生成的闭环中：

1. 奖励函数编写（Eureka）：LLM 接收任务描述（如“让四足机器人在瑜伽球上保持平衡”），自动编写并迭代优化奖励函数代码。
2. 物理先验探测（Reward-Aware Physics Prior, RAPP）：在仿真中使用初步训练的策略进行测试，记录在不同物理参数（摩擦力、质量等）下的性能表现。
3. 域随机化配置（Domain Randomization, DR）：LLM 分析 RAPP 的结果，推理出最适合该任务的物理参数随机化范围。例如，如果 LLM 发现机器人在低摩擦力下容易摔倒，它会建议在训练数据中增加低摩擦力的样本比例，以增强鲁棒性。

#### 4.2.2 零样本迁移成果

实验结果表明，DrEureka 训练出的策略无需任何真实世界数据微调，即可在 四足机器人走瑜伽球 等高难度动态任务上实现 Zero-Shot 迁移。其生成的 DR 配置在鲁棒性上甚至优于人类专家精心调节的参数。

### 4.3 X-Mobility：端到端导航的合成数据流水线

X-Mobility  展示了如何完全依赖合成数据解决通用的端到端导航问题。

#### 4.3.1 Isaac Sim 中的多阶段数据策略

X-Mobility 利用 NVIDIA Isaac Sim 构建了一个分层的数据生成与训练管线：

- 第一阶段：随机策略数据（Random Policy Data）。让机器人在仿真环境中随机游走，采集海量的观测数据。这部分数据虽无明确目标，但包含了丰富的环境几何与动力学信息，用于预训练世界模型。
- 第二阶段：教师策略数据（Teacher Policy Data）。使用传统的导航算法（如 Nav2）生成从起点到终点的专家轨迹。这部分数据用于在预训练的世界模型基础上，训练动作策略头（Action Policy Head）。
- 成效：通过这种“无监督预训练 + 监督微调”的策略，X-Mobility 仅凭合成数据就实现了在真实复杂环境中的鲁棒导航，且在动态避障能力上超越了传统的几何导航方法。

---

## 5. 通用具身策略模型（VLA）的架构演进

在世界模型和合成数据的支撑下，通用的“视觉-语言-动作”（Vision-Language-Action, VLA）模型在2024-2025年迎来了架构上的重大升级。

### 5.1 Open X-Embodiment：跨具身数据的标准化与统一

Open X-Embodiment (OxE)  是具身智能领域的“ImageNet”。它通过标准化的数据格式，打破了不同机器人硬件之间的数据壁垒。

#### 5.1.1 数据集的统一化构建

- 规模与多样性：OxE 汇集了来自全球 21 个机构的 60 个现有数据集，包含 100万+ 条真实轨迹，覆盖 22种 机器人形态。
- RLDS 格式与动作空间统一：所有数据被转换为 RLDS (Reinforcement Learning Datasets) 格式。为了解决不同机器人自由度不一致的问题，OxE 采用了一个 7-DoF 的统一动作空间：$(x, y, z, roll, pitch, yaw, gripper)$。对于自由度较少的机器人，对应的无效维度被置零。
- 视觉标准化：所有数据选取一个主要相机视角，并调整为统一的分辨率。

#### 5.1.2 正向迁移（Positive Transfer）

基于 OxE 训练的 RT-X 模型展示了显著的正向迁移效应。实验表明，利用与其形态不同的机器人数据进行联合训练（Co-training），可以使特定机器人的任务成功率提升 50%。这证明了物理操作技能在一定程度上是跨具身通用的。

### 5.2 Physical Intelligence $\pi_0$：流匹配与混合专家架构

Physical Intelligence 公司推出的 $\pi_0$  代表了 VLA 模型的最新技术高地。

#### 5.2.1 流匹配（Flow Matching）与 50Hz 控制

传统的扩散策略虽然效果好，但推理速度慢，难以满足机器人高频控制的需求。$\pi_0$ 引入了 流匹配 技术：

- 技术原理：流匹配通过学习一个确定性的向量场（Vector Field），将噪声分布平滑地推向目标动作分布。与扩散模型的随机路径不同，流匹配生成的轨迹更直，通常只需一步或极少步数的数值积分即可解码出动作。
- 实际意义：这使得 $\pi_0$ 能够以 50Hz 的频率输出平滑、连续的动作轨迹，解决了大模型推理延迟导致的控制卡顿问题。

#### 5.2.2 异构数据共训与 VLM+Action 架构

- 数据策略：$\pi_0$ 不仅使用了 OxE 和 DROID 等公开数据，还结合了 10,000+ 小时 的私有机器人数据，涵盖了多种完全不同的硬件平台。
- MoE 风格架构：为了兼顾语义理解与动作控制，$\pi_0$ 采用了一种分离设计：
   - VLM 主干：基于 PaliGemma (3B)，负责处理图像和文本指令，提取高层语义。
   - 动作专家：一个较小的 Gemma (300M) Transformer，专门负责接收 VLM 的特征并解码为具体的电机指令。
   - 这种设计允许模型在拥有几十亿参数语义理解能力的同时，保持动作生成的轻量化和高响应速度。

---

## 6. 人形机器人与长程任务：非结构化数据的利用

对于人形机器人（Humanoid）和长程任务（Long-Horizon Tasks），简单的数据模仿已经失效，需要更高层的数据抽象和规划能力。

### 6.1 HumanPlus：影子系统与全栈复刻

HumanPlus  展示了如何利用人类数据快速训练人形机器人。

- 影子采集系统（Shadowing）：为了获取高质量的机器人本体感数据，HumanPlus 首先在仿真中利用人类动作数据（AMASS）训练了一个“影子策略”，使机器人能实时跟随操作员的动作。
- 数据采集：操作员站在机器人身后，通过简单的 RGB 摄像头捕捉自身动作，机器人实时模仿完成任务（如叠衣服、搬运）。这种方式采集的数据天然包含了机器人的视觉和关节信息，且无需复杂的遥操作硬件。
- 数据量：仅需每个任务 40条 左右的演示，配合监督行为克隆（SBC），即可在真实世界达到高成功率。

### 6.2 LUMOS：非结构化游戏数据中的潜在规划

LUMOS  挑战了利用 无明确目标的玩耍数据（Play Data） 进行学习。

- 数据挑战：使用 CALVIN 数据集，其中仅有不到 1% 的数据带有语言标签。
- 训练方法：LUMOS 训练了一个潜在空间的世界模型。在训练时，它使用 事后目标重标记（Hindsight Goal Relabeling） 技术，将未来的随机状态设为目标，训练策略去达成它。对于那 1% 有标签的数据，模型学习将语言指令对齐到潜在目标状态。
- 推理：在执行长程任务时，模型首先在潜在空间中规划出一系列中间目标状态（Sub-goals），然后由策略网络逐步执行。这种方法显著提升了模型在未见指令下的泛化能力和长程任务的一致性。

---

## 7. 结论

2024-2025年的具身智能研究呈现出清晰的技术演进脉络：数据正在从“量”向“质”和“结构”转变，模型正在从“拟合”向“理解”和“推理”跃迁。

1. 数据来源的结构性变革：互联网视频不再是单纯的视觉素材，而是物理规律的载体。通过 Cosmos Curator 和 V-JEPA 2 的掩码训练，被动观察数据转化为主动的物理先验。同时，ManiSkill3 和 X-Mobility 证明了 GPU 并行仿真生成的合成数据在规模和多样性上已具备压倒性优势。
2. 训练范式的物理一致性：无论是 Vid2World 的因果化改造，还是 Geni 的潜在动作推理，核心都在于强迫模型遵守物理世界的因果律。
3. 策略模型的实时化与通用化：$\pi_0$ 的流匹配技术和 Open X-Embodiment 的跨具身训练，正在逐步消除异构硬件之间的隔阂，使“通用机器人大脑”的雏形初现。

未来，随着数据管线的进一步自动化（如 DrEureka 的 LLM 闭环）和世界模型推理能力的增强，我们有理由期待具身智能将在更复杂的物理交互任务中展现出接近人类的泛化能力。